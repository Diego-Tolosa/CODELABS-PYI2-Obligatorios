{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ff9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\SemestreActual\\ProyectoIntegrador2\\CODELABS-PYI2\\codelab5\\DeteccionImgsYoloLite\\..\\DeteccionImgsYoloLite\\imgs\\grupo.jpg: 448x640 14 persons, 72.1ms\n",
      "Speed: 2.1ms preprocess, 72.1ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "conf: tensor([0.8995, 0.8930, 0.8854, 0.8620, 0.7444, 0.7297, 0.7288, 0.7199, 0.5613, 0.5486, 0.4948, 0.3535, 0.3019, 0.2926])\n",
      "data: tensor([[4.2313e+02, 1.6004e+02, 5.6127e+02, 3.9568e+02, 8.9953e-01, 0.0000e+00],\n",
      "        [2.0974e+02, 7.2221e+01, 3.4220e+02, 3.9546e+02, 8.9303e-01, 0.0000e+00],\n",
      "        [3.0635e+02, 1.5281e+02, 4.3359e+02, 3.9516e+02, 8.8539e-01, 0.0000e+00],\n",
      "        [8.5777e+01, 1.5600e+02, 2.3352e+02, 3.9557e+02, 8.6196e-01, 0.0000e+00],\n",
      "        [1.5612e+02, 3.1047e+01, 2.6324e+02, 1.7549e+02, 7.4439e-01, 0.0000e+00],\n",
      "        [4.3757e+02, 7.7381e+01, 5.4930e+02, 2.4425e+02, 7.2972e-01, 0.0000e+00],\n",
      "        [0.0000e+00, 1.4336e+02, 9.5520e+01, 3.9413e+02, 7.2876e-01, 0.0000e+00],\n",
      "        [5.3788e+02, 1.3431e+02, 5.9987e+02, 3.9440e+02, 7.1992e-01, 0.0000e+00],\n",
      "        [7.7235e+01, 6.0307e+01, 1.5877e+02, 2.4881e+02, 5.6135e-01, 0.0000e+00],\n",
      "        [3.2012e+02, 9.3998e+01, 3.7877e+02, 1.7228e+02, 5.4857e-01, 0.0000e+00],\n",
      "        [3.8186e+02, 9.5883e+01, 4.7133e+02, 3.7851e+02, 4.9479e-01, 0.0000e+00],\n",
      "        [3.3313e+01, 1.0963e+02, 1.0386e+02, 2.5098e+02, 3.5353e-01, 0.0000e+00],\n",
      "        [1.5862e+02, 9.8265e+01, 2.2994e+02, 2.1533e+02, 3.0189e-01, 0.0000e+00],\n",
      "        [3.2629e+01, 1.1060e+02, 1.1029e+02, 3.8095e+02, 2.9262e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (400, 600)\n",
      "shape: torch.Size([14, 6])\n",
      "xywh: tensor([[492.2026, 277.8586, 138.1443, 235.6411],\n",
      "        [275.9710, 233.8405, 132.4528, 323.2399],\n",
      "        [369.9675, 273.9844, 127.2429, 242.3471],\n",
      "        [159.6483, 275.7863, 147.7432, 239.5719],\n",
      "        [209.6808, 103.2690, 107.1145, 144.4444],\n",
      "        [493.4340, 160.8165, 111.7307, 166.8705],\n",
      "        [ 47.7600, 268.7436,  95.5200, 250.7680],\n",
      "        [568.8754, 264.3562,  61.9939, 260.0894],\n",
      "        [118.0024, 154.5566,  81.5345, 188.4990],\n",
      "        [349.4423, 133.1417,  58.6456,  78.2864],\n",
      "        [426.5950, 237.1947,  89.4733, 282.6236],\n",
      "        [ 68.5886, 180.3027,  70.5510, 141.3497],\n",
      "        [194.2812, 156.7955,  71.3129, 117.0612],\n",
      "        [ 71.4584, 245.7783,  77.6592, 270.3508]])\n",
      "xywhn: tensor([[0.8203, 0.6946, 0.2302, 0.5891],\n",
      "        [0.4600, 0.5846, 0.2208, 0.8081],\n",
      "        [0.6166, 0.6850, 0.2121, 0.6059],\n",
      "        [0.2661, 0.6895, 0.2462, 0.5989],\n",
      "        [0.3495, 0.2582, 0.1785, 0.3611],\n",
      "        [0.8224, 0.4020, 0.1862, 0.4172],\n",
      "        [0.0796, 0.6719, 0.1592, 0.6269],\n",
      "        [0.9481, 0.6609, 0.1033, 0.6502],\n",
      "        [0.1967, 0.3864, 0.1359, 0.4712],\n",
      "        [0.5824, 0.3329, 0.0977, 0.1957],\n",
      "        [0.7110, 0.5930, 0.1491, 0.7066],\n",
      "        [0.1143, 0.4508, 0.1176, 0.3534],\n",
      "        [0.3238, 0.3920, 0.1189, 0.2927],\n",
      "        [0.1191, 0.6144, 0.1294, 0.6759]])\n",
      "xyxy: tensor([[423.1305, 160.0381, 561.2748, 395.6791],\n",
      "        [209.7446,  72.2206, 342.1974, 395.4604],\n",
      "        [306.3461, 152.8109, 433.5889, 395.1580],\n",
      "        [ 85.7767, 156.0004, 233.5199, 395.5722],\n",
      "        [156.1236,  31.0468, 263.2381, 175.4912],\n",
      "        [437.5686,  77.3813, 549.2993, 244.2518],\n",
      "        [  0.0000, 143.3596,  95.5200, 394.1275],\n",
      "        [537.8784, 134.3115, 599.8723, 394.4009],\n",
      "        [ 77.2351,  60.3071, 158.7697, 248.8061],\n",
      "        [320.1195,  93.9985, 378.7651, 172.2849],\n",
      "        [381.8584,  95.8829, 471.3317, 378.5065],\n",
      "        [ 33.3131, 109.6279, 103.8641, 250.9776],\n",
      "        [158.6247,  98.2649, 229.9377, 215.3262],\n",
      "        [ 32.6288, 110.6029, 110.2880, 380.9537]])\n",
      "xyxyn: tensor([[0.7052, 0.4001, 0.9355, 0.9892],\n",
      "        [0.3496, 0.1806, 0.5703, 0.9887],\n",
      "        [0.5106, 0.3820, 0.7226, 0.9879],\n",
      "        [0.1430, 0.3900, 0.3892, 0.9889],\n",
      "        [0.2602, 0.0776, 0.4387, 0.4387],\n",
      "        [0.7293, 0.1935, 0.9155, 0.6106],\n",
      "        [0.0000, 0.3584, 0.1592, 0.9853],\n",
      "        [0.8965, 0.3358, 0.9998, 0.9860],\n",
      "        [0.1287, 0.1508, 0.2646, 0.6220],\n",
      "        [0.5335, 0.2350, 0.6313, 0.4307],\n",
      "        [0.6364, 0.2397, 0.7856, 0.9463],\n",
      "        [0.0555, 0.2741, 0.1731, 0.6274],\n",
      "        [0.2644, 0.2457, 0.3832, 0.5383],\n",
      "        [0.0544, 0.2765, 0.1838, 0.9524]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'resultado_yolo.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO  \n",
    "import time\n",
    "  \n",
    "# Cargar el modelo nano (rápido y liviano)  \n",
    "model = YOLO(\"yolov8n.pt\")  \n",
    "  \n",
    "# --- Detección en una imagen ---  \n",
    "image_path = \"../DeteccionImgsYoloLite/imgs/grupo.jpg\"  # cámbialo por tu imagen  \n",
    "t2 = time.time()  \n",
    "results = model(image_path)  \n",
    "t3 = time.time()\n",
    "  \n",
    "# Mostrar resultados  \n",
    "for r in results:  \n",
    "    print(r.names)  # clases disponibles  \n",
    "    print(r.boxes)  # cajas detectadas  \n",
    "  \n",
    "# Guardar imagen con anotaciones  \n",
    "results[0].save(filename=\"resultado_yolo.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
